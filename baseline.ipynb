{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from itertools import *\n",
    "from functools import *\n",
    "from collections import defaultdict\n",
    "\n",
    "import rep\n",
    "import rep.data\n",
    "\n",
    "import sklearn\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.decomposition\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from overloading import overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PREFIX = 'data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('{}/{}'.format(os.getcwd(),\n",
    "                        DATA_PREFIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_likes_file = open('train_likes.csv')\n",
    "reader = csv.DictReader(train_likes_file)\n",
    "train_likes = map(lambda row: (row['user_id'], row['item_id']), reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list(islice(train_likes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dict():\n",
    "    for user, item in train_likes:\n",
    "        yield {'user_id': user, 'item_id': item}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.DictVectorizer(dtype=np.bool)\n",
    "user_item = vectorizer.fit_transform(get_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\DeclareMathOperator*{\\argmin}{arg\\,min}$\n",
    "There are two different ways to look at the truncated SVD of a matrix. One is the standard definition:\n",
    "\n",
    "> First you do the SVD: $\\underset{n\\times m}{X} = \\underset{n\\times n}{U} \\overset{n\\times m}{\\Sigma} \\underset{m\\times m}{V^T}$, where $U$ and $V$ are rotation matrices, and $\\Sigma$ has the singular values along the diagonal. Then you pick the top $k$ singular values, zero out the rest, and hack off irrelevant rows and columns to make a $k$-rank approximation to the original: $X \\approx \\tilde{X} = \\underset{n\\times k}{\\tilde{U}} \\overset{k\\times k}{\\tilde{\\Sigma}} \\underset{k\\times m}{\\tilde{V}^T}$\n",
    "\n",
    "This is all fine and dandy, but it doesn't make sense when talking about matrices with missing values. However, there's an interesting property of the $k$-truncated SVD--It's the best $k$-rank approximation to the original! That is:\n",
    "\n",
    "> $ \\tilde{X} = \\argmin_{B : rank(B)=k} \\displaystyle\\sum\\limits_{i,j} (X_{ij} - B_{ij})^2$\n",
    "\n",
    "This property seems easy to generalize to the missing value case. Basically you're looking for a $k$-rank matrix that minimizes the element-wise mean squared error across the known entries of the original matrix. That is, when you're training the system, you ignore all of the missing values.\n",
    "\n",
    "Then, once you've come up with a suitably \"close\" $k$-rank approximation to the original, you use it to fill in the missing values. That is, if $X_{ij}$ was missing, then you fill in $\\tilde{X}_{ij}$. Tada! You are now done.\n",
    "\n",
    "-- http://stats.stackexchange.com/a/35460"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u, s, v = sp.sparse.linalg.svds(user_item.astype(np.float32), k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u.shape, s.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the matrix A be such that rows are the users and the columns are the items that the user likes. One way to think of SVD is as follows: SVD finds a hidden feature space where the users and items they like have feature vectors that are closely aligned.\n",
    "\n",
    "So, when we compute $A = U \\times s \\times V$, the $U$ matrix represents the feature vectors corresponding to the users in the hidden feature space and the $V$ matrix represents the feature vectors corresponding to the items in the hidden feature space.\n",
    "\n",
    "Now, if I give you two vectors from the same feature space and ask you to find if they are similar, what is the simplest thing that you can think of for accomplishing that? Dot product.\n",
    "\n",
    "So, if I want to see user $i$ likes item $j$, all I need to do is take the dot product of the $i$th entry in $U$ and $j$th entry in V. Of course, dot product is by no means the only thing you can apply, any similarity measure that you can think of is applicable.\n",
    "\n",
    "-- http://stats.stackexchange.com/a/31101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(u[:10,], v) # get the probabilities for first ten users -> all films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(u[1,:], v[:,546]) # get the probabilities for user 1 -> film 546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended interface\n",
    "```python\n",
    "get_like_likelihood(user_id: str, item_id: str) -> float\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def get_like_likelihood(user_id: int, item_id: int) -> float:\n",
    "    return np.dot(u[user_id,:], v[:,item_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vectorized_id(mapping: str) -> int:\n",
    "    return vectorizer.vocabulary_[mapping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def get_like_likelihood(user_id: str, item_id: str) -> float:\n",
    "    user_id_v = get_vectorized_id('user_id={}'.format(user_id))\n",
    "    item_id_v = get_vectorized_id('item_id={}'.format(item_id))\n",
    "    \n",
    "    return get_like_likelihood(user_id_v, item_id_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_like_likelihood('70a2805f307f49ec42d4309190daa587', '0ccd2d96eb4b393ecb8cf4e55a6544b6')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

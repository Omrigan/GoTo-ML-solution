{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import json\n",
    "from metrics import apk\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Словари для основной выборки\n",
    "user_to_items = defaultdict(set)\n",
    "item_to_users = defaultdict(set)\n",
    "edges = []\n",
    "#Словари для тестовой выборки\n",
    "test_user_to_items = defaultdict(set)\n",
    "test_item_to_users = defaultdict(set)\n",
    "test_edges = []\n",
    "\n",
    "with open(\"data/train_likes.csv\") as datafile:\n",
    "    for like in csv.DictReader(datafile):\n",
    "        # Кидаем монетку. В зависимости от результата кладём в обучение или тест\n",
    "        if random.random() < 0.90:\n",
    "            user_to_items[like['user_id']].add(like['item_id'])\n",
    "            item_to_users[like['item_id']].add(like['user_id'])\n",
    "            edges.append((like['user_id'], like['item_id']))\n",
    "        else:\n",
    "            test_user_to_items[like['user_id']].add(like['item_id'])\n",
    "            test_item_to_users[like['item_id']].add(like['user_id'])\n",
    "            test_edges.append((like['user_id'], like['item_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_items = set(item_to_users.keys()) | set(test_item_to_users.keys())\n",
    "all_users = set(user_to_items.keys()) | set(test_user_to_items.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_list = list(user_to_items.keys())\n",
    "test_users_list = list(test_user_to_items.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_to_i = {user: i for i, user in enumerate(all_users)}\n",
    "item_to_i = {item: i for i, item in enumerate(all_items)}\n",
    "all_users_list = list(all_users)\n",
    "all_items_list = list(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matrix = sp.sparse.lil_matrix((len(all_users), len(all_items)))\n",
    "test_matrix = sp.sparse.lil_matrix((len(all_users), len(all_items)))\n",
    "for user, items in user_to_items.items():\n",
    "    for item in items:\n",
    "        matrix[user_to_i[user], item_to_i[item]] = True\n",
    "for user, items in test_user_to_items.items():\n",
    "    for item in items:\n",
    "        test_matrix[user_to_i[user], item_to_i[item]] = True\n",
    "matrix = matrix.tocsr()\n",
    "test_matrix = test_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<55863x23891 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 99582 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u, s, vt = sp.sparse.linalg.svds(matrix.astype(np.float32), k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55863, 100), (100,), (100, 23891))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.shape, s.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "films = json.load(open('data/items.json'))\n",
    "films = {a['id']:a for a in films}\n",
    "for a in films.values():\n",
    "    del a['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in films.values():\n",
    "    if 'genre' in f:\n",
    "        f[f['genre']] = 1\n",
    "        del f['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = Counter()\n",
    "for f in films.values():\n",
    "    features.update(set(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('year', 138078),\n",
       " ('duration', 138078),\n",
       " (0, 34128),\n",
       " (3, 32154),\n",
       " ('f_114306', 30650),\n",
       " (1, 28635),\n",
       " ('f_79251', 16647),\n",
       " ('f_117573', 15295),\n",
       " ('f_138980', 15215),\n",
       " (5, 15008),\n",
       " ('f_64513', 14020),\n",
       " ('f_205162', 10693),\n",
       " ('f_122038', 10436),\n",
       " ('f_84602', 8377),\n",
       " ('f_68894', 8348),\n",
       " ('f_127793', 7946),\n",
       " ('f_72071', 7866),\n",
       " (4, 7386),\n",
       " ('f_210900', 7085),\n",
       " ('f_130202', 6371)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_features_size = 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_features = set([_[0] for _ in features.most_common(small_features_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_to_i = {feature: i for i, feature in enumerate(small_features)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 1,\n",
       " 2: 6,\n",
       " 3: 3,\n",
       " 4: 4,\n",
       " 5: 5,\n",
       " 6: 8,\n",
       " 'f_84602': 2,\n",
       " 'f_127828': 10,\n",
       " 'f_79251': 9,\n",
       " 'f_83623': 12,\n",
       " 'f_93782': 14,\n",
       " 'f_151440': 15,\n",
       " 'f_165994': 18,\n",
       " 'f_46479': 17,\n",
       " 'f_69077': 38,\n",
       " 'f_64718': 28,\n",
       " 'f_49558': 19,\n",
       " 'f_93783': 20,\n",
       " 'f_429': 13,\n",
       " 'f_205164': 21,\n",
       " 'f_110758': 22,\n",
       " 'f_163241': 23,\n",
       " 'f_187493': 24,\n",
       " 'f_114306': 25,\n",
       " 7: 7,\n",
       " 'f_210900': 27,\n",
       " 'f_253': 29,\n",
       " 8: 11,\n",
       " 'f_71149': 30,\n",
       " 'f_64513': 26,\n",
       " 'f_140034': 31,\n",
       " 'f_72071': 32,\n",
       " 'f_44763': 33,\n",
       " 'f_173938': 40,\n",
       " 'f_121936': 36,\n",
       " 'f_109358': 37,\n",
       " 'duration': 58,\n",
       " 'f_127794': 39,\n",
       " 'year': 41,\n",
       " 'f_197169': 43,\n",
       " 'f_122038': 44,\n",
       " 'f_130202': 45,\n",
       " 'f_138980': 46,\n",
       " 'f_68894': 47,\n",
       " 'f_117573': 48,\n",
       " 'f_188358': 49,\n",
       " 'f_55703': 50,\n",
       " 'f_89959': 51,\n",
       " 'f_154169': 52,\n",
       " 'f_144994': 34,\n",
       " 'f_71282': 42,\n",
       " 'f_187216': 53,\n",
       " 'f_49716': 35,\n",
       " 'f_203955': 55,\n",
       " 'f_127793': 56,\n",
       " 'f_168177': 57,\n",
       " 'f_44580': 54,\n",
       " 'f_205162': 59,\n",
       " 'f_99688': 16}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фильтрация пользователей\n",
    "* Значительная часть пользователей имеет всего 1-2 просмотра. При всём желании, рекоммендовать им что-либо осмысленное при помощи рассматриваемого здесь метода мы вряд ли сможем. Для простоты вычислений, удалим их из выборки.\n",
    "* Важно понимать, что качество на оставшихся пользователях скорее всего будет выше, чем на первоначальной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_items_per_user = 2\n",
    "from copy import copy\n",
    "for user in copy(test_user_to_items).keys():\n",
    "    \n",
    "    n_items_per_user = len(user_to_items[user]) + len(test_user_to_items[user])\n",
    "    \n",
    "    if n_items_per_user <= min_items_per_user:\n",
    "        del user_to_items[user]\n",
    "        del test_user_to_items[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекоммендующая функция\n",
    "Позволим себе немного вольности: наша функция будет возвращать не вероятности, а список фильмов в порядке убывания \"рекомендованности\".\n",
    "\n",
    "* Рекоммендованность фильма item пользователю user посчитаем так:\n",
    "  * Для каждого фильма, полайканного пользователем user, найдём других людей, которым понравился фильм.\n",
    "  * Сложим всех таких \"друзей по лайкам\" вместе и назовём соседями (__neighborhood__) пользователя.\n",
    "  * Для фильма item узнаем его аудиторию - множество пользователей, которые его лайкнули\n",
    "  * Пригодность фильма пользователю - то, насколько \"друзьям по лайкам\" пользователя нравится этот фильм.\n",
    "\n",
    "Для примера, будем использовать косинусную меру расстояния\n",
    "  \n",
    "$ cos(u_{film}, u_{neighborhood}) = $ =$ u_{film} \\cdot u_{neighborhood} \\over |u_{film}| |u_{neighborhood}| $\n",
    "\n",
    "\n",
    "$u_{neighborhood}$ зависит только от пользователя, но не от фильма, поэтому при сравнении фильмов по пригодности для одного пользователя, его можно исключить из формулы для простоты вычислений.\n",
    "\n",
    "$ similarity(u_{film}, u_{neighborhood}) = $ $  u_{film} \\cdot u_{neighborhood} \\over |u_{film}| $\n",
    "  \n",
    "  \n",
    "Распишем формулу подробно:\n",
    "\n",
    "$ similarity(u_{film}, u_{neighborhood}) = $ $ \\sum _{u_i} [u_i \\in u_{film}] \\cdot [u_i \\in u_{neighborhood}] \\over |u_{film}|  $\n",
    "\n",
    "* u_i - очередной пользователь (в цикле по всем пользователям)\n",
    "  \n",
    "Выражение $[u_i \\in u_{neighborhood}]$ здесь означает \"сколько раз очередной пользователь входит в множество друзей по лайкам\"\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from collections import Counter\n",
    "\n",
    "def recommend(user, n_best = 10):\n",
    "    user_items = user_to_items[user]\n",
    "    \n",
    "    neighborhood = Counter()\n",
    "    for item in user_items:\n",
    "        neighborhood.update(item_to_users[item])\n",
    "    \n",
    "    #словарь {фильм -> пригодность фильма пользователю}\n",
    "    item_similarities = {}\n",
    "    \n",
    "    for item in all_items:\n",
    "        if item in user_items: continue\n",
    "        item_users = item_to_users[item]\n",
    "        if len(item_users) == 0: continue\n",
    "        \n",
    "        n_common_users = sum(neighborhood[user] for user in item_users)\n",
    "        similarity = float(n_common_users) / sqrt(len(item_users))\n",
    "        item_similarities[item] = similarity\n",
    "    \n",
    "    items_sorted = sorted(all_items, key = lambda x: item_similarities.get(x, 0),reverse = True)\n",
    "    \n",
    "    return items_sorted[:n_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_to_int = dict()\n",
    "for i, user in enumerate(all_users):\n",
    "    user_to_int[user] = i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Making dataset\n",
    "user_features = defaultdict(lambda:defaultdict(lambda:0))\n",
    "for user in list(user_to_items.keys())[0:]:\n",
    "    for item in user_to_items[user]:\n",
    "        if item in films:\n",
    "            for feature, value in films[item].items():    \n",
    "                user_features[user][feature]+=value\n",
    "    for f in user_features[user]:\n",
    "        user_features[user][f]/=len(user_to_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges[0] in test_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_size = 2*small_features_size + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(user=None, item=None, X_sample = np.zeros(features_size, dtype='float32')):\n",
    "    if user is not None:\n",
    "        for f in user_features[user].keys()&small_features:\n",
    "            X_sample[feature_to_i[f]] = user_features[user][f]\n",
    "        if item is not None:\n",
    "            X_sample[2*small_features_size+0] = user_film_mk2(user, item)\n",
    "    if item is not None and item in films:\n",
    "        for f in films[item].keys()&small_features:\n",
    "            X_sample[small_features_size+feature_to_i[f]] = films[item][f]\n",
    "    \n",
    "    return X_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100068"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_random_samples(X_size = 100, use_test=False):\n",
    "    X = np.zeros((X_size, features_size), dtype='float32')\n",
    "    Y = np.zeros(X_size, dtype='int8')\n",
    "    if use_test:\n",
    "        local_users_list = test_users_list\n",
    "        local_user_to_items = test_user_to_items\n",
    "    else:\n",
    "        local_users_list = users_list\n",
    "        local_user_to_items = user_to_items\n",
    "    for i in range(X_size):\n",
    "        film =''\n",
    "        while film not in films: \n",
    "            result = random.random()\n",
    "            if result > 0.50:\n",
    "                result = 1\n",
    "            else:\n",
    "                result = 0\n",
    "            user = random.choice(local_users_list)\n",
    "            if result==0:\n",
    "                film = random.choice(all_items_list)\n",
    "                if film in local_user_to_items[user]:\n",
    "                    result = 1\n",
    "            else:\n",
    "                film = random.choice(list(local_user_to_items[user]|{''}))\n",
    "        X[i] = extract_features(user, film)\n",
    "        Y[i] = result\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_samples(X_true = 100,  use_test=False):\n",
    "    X_fake=X_true\n",
    "    X = np.zeros((X_true+X_fake, features_size), dtype='float32')\n",
    "    Y = np.zeros(X_true+X_fake, dtype='float32')\n",
    "    if use_test:\n",
    "        local_users_list = test_users_list\n",
    "        local_user_to_items = test_user_to_items\n",
    "        local_edges = test_edges \n",
    "    else: \n",
    "        local_users_list = users_list\n",
    "        local_user_to_items = user_to_items\n",
    "        local_edges = edges\n",
    "    for i, (user, film)  in enumerate(local_edges[:X_true]):\n",
    "        X[i] = extract_features(user, film)\n",
    "        Y[i] = 1\n",
    "    for i in range(X_true, X_true+X_fake):\n",
    "        user = random.choice(local_users_list)\n",
    "        film = random.choice(all_items_list)\n",
    "        X[i] = extract_features(user, film)\n",
    "        if film in local_user_to_items[user]:\n",
    "            Y[i] = 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, Y = generate_random_samples(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-254-947ff9859be2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 290\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.878675890313\n",
      "Test score: 0.202766900421\n"
     ]
    }
   ],
   "source": [
    "X, Y = generate_random_samples(100, use_test=False)\n",
    "print(\"Train score: %s\" %(rf.score(X, Y),))\n",
    "X, Y = generate_random_samples(100, use_test=True)\n",
    "print(\"Test score: %s\" %(rf.score(X, Y),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_X = T.matrix(\"input X\")\n",
    "input_shape = [None, features_size]\n",
    "\n",
    "target_y = T.matrix(\"target Y integer\",dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input layer (auxilary)\n",
    "layer = lasagne.layers.InputLayer(shape = input_shape,input_var=input_X)\n",
    "\n",
    "#fully connected layer, that takes input layer and applies 50 neurons to it.\n",
    "# nonlinearity here is sigmoid as in logistic regression\n",
    "# you can give a name to each layer (optional)\n",
    "layer = lasagne.layers.BatchNormLayer(layer)\n",
    "\n",
    "layer = lasagne.layers.DenseLayer(layer,num_units=50,\n",
    "                                   nonlinearity = lasagne.nonlinearities.rectify,\n",
    "                                   name = \"hidden_dense_layer\")\n",
    "layer = lasagne.layers.DenseLayer(layer,num_units=50,\n",
    "                                   nonlinearity = lasagne.nonlinearities.rectify,\n",
    "                                   name = \"hidden_dense_layer\")\n",
    "layer = lasagne.layers.DenseLayer(layer,num_units=20,\n",
    "                                   nonlinearity = lasagne.nonlinearities.rectify,\n",
    "                                   name = \"hidden_dense_layer\")\n",
    "\n",
    "layer = lasagne.layers.DropoutLayer(layer, p=0.5)\n",
    "\n",
    "#fully connected output layer that takes dense_1 as input and has 10 neurons (1 for each digit)\n",
    "#We use softmax nonlinearity to make probabilities add up to 1\n",
    "dense_output = lasagne.layers.DenseLayer(layer,num_units = 1 ,\n",
    "                                        nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                                        name='output', b=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[beta, gamma, hidden_dense_layer.W, hidden_dense_layer.b, hidden_dense_layer.W, hidden_dense_layer.b, hidden_dense_layer.W, hidden_dense_layer.b, output.W]\n"
     ]
    }
   ],
   "source": [
    "#network prediction (theano-transformation)\n",
    "y_predicted = lasagne.layers.get_output(dense_output)\n",
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(dense_output, trainable=True)\n",
    "\n",
    "predict = theano.function([input_X], y_predicted)\n",
    "print (all_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = lasagne.objectives.squared_error(y_predicted, target_y)\n",
    "loss = lasagne.objectives.aggregate(loss, mode = 'mean')\n",
    "\n",
    "\n",
    "updates_sgd = lasagne.updates.sgd(loss, all_weights,learning_rate=0.01)\n",
    "\n",
    "train_fun = theano.function([input_X,target_y],loss,updates= updates_sgd)\n",
    "\n",
    "\n",
    "loss_fun = theano.function([input_X,target_y],loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1000 took 2.108s\n",
      "  train loss: 0.306663180382\n",
      "  test loss: 0.268406966676\n",
      "Epoch 2 of 1000 took 1.871s\n",
      "  train loss: 0.19022252031\n",
      "  test loss: 0.254713715841\n",
      "Epoch 3 of 1000 took 1.493s\n",
      "  train loss: 0.141657775006\n",
      "  test loss: 0.257853657044\n",
      "Epoch 4 of 1000 took 1.551s\n",
      "  train loss: 0.122874053737\n",
      "  test loss: 0.249679538303\n",
      "Epoch 5 of 1000 took 1.537s\n",
      "  train loss: 0.110237962803\n",
      "  test loss: 0.245874756396\n",
      "Epoch 6 of 1000 took 1.527s\n",
      "  train loss: 0.102485726024\n",
      "  test loss: 0.252908689012\n",
      "Epoch 7 of 1000 took 1.555s\n",
      "  train loss: 0.0918034182174\n",
      "  test loss: 0.251809832181\n",
      "Epoch 8 of 1000 took 1.556s\n",
      "  train loss: 0.0867714483947\n",
      "  test loss: 0.25587180903\n",
      "Epoch 9 of 1000 took 1.652s\n",
      "  train loss: 0.0841423032619\n",
      "  test loss: 0.254131689618\n",
      "Epoch 10 of 1000 took 1.554s\n",
      "  train loss: 0.0805386086999\n",
      "  test loss: 0.253550310658\n",
      "Epoch 11 of 1000 took 1.681s\n",
      "  train loss: 0.0804888609038\n",
      "  test loss: 0.24851584096\n",
      "Epoch 12 of 1000 took 1.592s\n",
      "  train loss: 0.0785525323193\n",
      "  test loss: 0.249294105016\n",
      "Epoch 13 of 1000 took 1.559s\n",
      "  train loss: 0.072251591567\n",
      "  test loss: 0.242418721063\n",
      "Epoch 14 of 1000 took 1.998s\n",
      "  train loss: 0.0748320442739\n",
      "  test loss: 0.26011918813\n",
      "Epoch 15 of 1000 took 1.627s\n",
      "  train loss: 0.0750755448649\n",
      "  test loss: 0.251531296675\n",
      "Epoch 16 of 1000 took 2.154s\n",
      "  train loss: 0.0706481899889\n",
      "  test loss: 0.256290965245\n",
      "Epoch 17 of 1000 took 1.724s\n",
      "  train loss: 0.0671241526627\n",
      "  test loss: 0.257412407463\n",
      "Epoch 18 of 1000 took 1.629s\n",
      "  train loss: 0.0636477744852\n",
      "  test loss: 0.248242819635\n",
      "Epoch 19 of 1000 took 1.480s\n",
      "  train loss: 0.0645860862817\n",
      "  test loss: 0.245547148074\n",
      "Epoch 20 of 1000 took 1.516s\n",
      "  train loss: 0.0623547482064\n",
      "  test loss: 0.259567996381\n",
      "Epoch 21 of 1000 took 1.588s\n",
      "  train loss: 0.0632322707913\n",
      "  test loss: 0.25777058252\n",
      "Epoch 22 of 1000 took 1.552s\n",
      "  train loss: 0.0623240422968\n",
      "  test loss: 0.252870355106\n",
      "Epoch 23 of 1000 took 1.567s\n",
      "  train loss: 0.0609455294057\n",
      "  test loss: 0.244092615458\n",
      "Epoch 24 of 1000 took 1.553s\n",
      "  train loss: 0.0643879035105\n",
      "  test loss: 0.253683691\n",
      "Epoch 25 of 1000 took 1.657s\n",
      "  train loss: 0.0591134756174\n",
      "  test loss: 0.259001438895\n",
      "Epoch 26 of 1000 took 1.642s\n",
      "  train loss: 0.0597349127867\n",
      "  test loss: 0.249675634405\n",
      "Epoch 27 of 1000 took 1.574s\n",
      "  train loss: 0.0575077852892\n",
      "  test loss: 0.249368503708\n",
      "Epoch 28 of 1000 took 1.663s\n",
      "  train loss: 0.0572355736961\n",
      "  test loss: 0.251874096723\n",
      "Epoch 29 of 1000 took 1.633s\n",
      "  train loss: 0.0546663328384\n",
      "  test loss: 0.253616850644\n",
      "Epoch 30 of 1000 took 1.513s\n",
      "  train loss: 0.0550655677241\n",
      "  test loss: 0.252548455539\n",
      "Epoch 31 of 1000 took 1.552s\n",
      "  train loss: 0.0559899046713\n",
      "  test loss: 0.249745212835\n",
      "Epoch 32 of 1000 took 1.564s\n",
      "  train loss: 0.0554047510518\n",
      "  test loss: 0.252018181072\n",
      "Epoch 33 of 1000 took 1.689s\n",
      "  train loss: 0.0543323216567\n",
      "  test loss: 0.258036206457\n",
      "Epoch 34 of 1000 took 1.640s\n",
      "  train loss: 0.0520794334636\n",
      "  test loss: 0.250266851468\n",
      "Epoch 35 of 1000 took 1.559s\n",
      "  train loss: 0.0537785171191\n",
      "  test loss: 0.25038294324\n",
      "Epoch 36 of 1000 took 1.488s\n",
      "  train loss: 0.0541575475142\n",
      "  test loss: 0.24984009799\n",
      "Epoch 37 of 1000 took 1.632s\n",
      "  train loss: 0.053049611315\n",
      "  test loss: 0.250113238699\n",
      "Epoch 38 of 1000 took 1.550s\n",
      "  train loss: 0.0546580263174\n",
      "  test loss: 0.241247246214\n",
      "Epoch 39 of 1000 took 1.597s\n",
      "  train loss: 0.0499777112769\n",
      "  test loss: 0.242356001615\n",
      "Epoch 40 of 1000 took 1.720s\n",
      "  train loss: 0.0509019139349\n",
      "  test loss: 0.240511314609\n",
      "Epoch 41 of 1000 took 1.535s\n",
      "  train loss: 0.0542111639046\n",
      "  test loss: 0.24704140382\n",
      "Epoch 42 of 1000 took 1.462s\n",
      "  train loss: 0.048363439654\n",
      "  test loss: 0.239643623761\n",
      "Epoch 43 of 1000 took 1.503s\n",
      "  train loss: 0.0492966661901\n",
      "  test loss: 0.244694379672\n",
      "Epoch 44 of 1000 took 1.477s\n",
      "  train loss: 0.0517237818777\n",
      "  test loss: 0.252688270179\n",
      "Epoch 45 of 1000 took 1.534s\n",
      "  train loss: 0.0544747185403\n",
      "  test loss: 0.238186038623\n",
      "Epoch 46 of 1000 took 1.483s\n",
      "  train loss: 0.0478573378707\n",
      "  test loss: 0.240517982476\n",
      "Epoch 47 of 1000 took 1.500s\n",
      "  train loss: 0.0504934675453\n",
      "  test loss: 0.243623746912\n",
      "Epoch 48 of 1000 took 1.470s\n",
      "  train loss: 0.0487199786612\n",
      "  test loss: 0.240775333117\n",
      "Epoch 49 of 1000 took 1.484s\n",
      "  train loss: 0.0479088583627\n",
      "  test loss: 0.249902526519\n",
      "Epoch 50 of 1000 took 1.466s\n",
      "  train loss: 0.0496046821943\n",
      "  test loss: 0.251068508524\n",
      "Epoch 51 of 1000 took 1.477s\n",
      "  train loss: 0.047489616344\n",
      "  test loss: 0.247036978654\n",
      "Epoch 52 of 1000 took 1.600s\n",
      "  train loss: 0.0479921261648\n",
      "  test loss: 0.258146278409\n",
      "Epoch 53 of 1000 took 1.771s\n",
      "  train loss: 0.0456943703546\n",
      "  test loss: 0.252863535533\n",
      "Epoch 54 of 1000 took 1.879s\n",
      "  train loss: 0.0460550244487\n",
      "  test loss: 0.252785315729\n",
      "Epoch 55 of 1000 took 1.600s\n",
      "  train loss: 0.0458847488643\n",
      "  test loss: 0.254548571024\n",
      "Epoch 56 of 1000 took 1.901s\n",
      "  train loss: 0.0488692731838\n",
      "  test loss: 0.24657377313\n",
      "Epoch 57 of 1000 took 1.990s\n",
      "  train loss: 0.0470240404072\n",
      "  test loss: 0.251869069786\n",
      "Epoch 58 of 1000 took 1.674s\n",
      "  train loss: 0.0461469466433\n",
      "  test loss: 0.264373694483\n",
      "Epoch 59 of 1000 took 1.548s\n",
      "  train loss: 0.0481562183123\n",
      "  test loss: 0.249733611691\n",
      "Epoch 60 of 1000 took 1.519s\n",
      "  train loss: 0.0457805579825\n",
      "  test loss: 0.247633849546\n",
      "Epoch 61 of 1000 took 1.625s\n",
      "  train loss: 0.0445741192577\n",
      "  test loss: 0.256178396402\n",
      "Epoch 62 of 1000 took 1.730s\n",
      "  train loss: 0.0462442058408\n",
      "  test loss: 0.242534038326\n",
      "Epoch 63 of 1000 took 1.630s\n",
      "  train loss: 0.0428711697606\n",
      "  test loss: 0.258621137674\n",
      "Epoch 64 of 1000 took 1.665s\n",
      "  train loss: 0.0442718617647\n",
      "  test loss: 0.258193198705\n",
      "Epoch 65 of 1000 took 1.774s\n",
      "  train loss: 0.0463492782642\n",
      "  test loss: 0.265442252422\n",
      "Epoch 66 of 1000 took 1.891s\n",
      "  train loss: 0.0442471446204\n",
      "  test loss: 0.259342850996\n",
      "Epoch 67 of 1000 took 1.806s\n",
      "  train loss: 0.0435668545433\n",
      "  test loss: 0.260707493237\n",
      "Epoch 68 of 1000 took 1.687s\n",
      "  train loss: 0.0418230534443\n",
      "  test loss: 0.266351000086\n",
      "Epoch 69 of 1000 took 1.567s\n",
      "  train loss: 0.043834384931\n",
      "  test loss: 0.25832421946\n",
      "Epoch 70 of 1000 took 1.585s\n",
      "  train loss: 0.0451774922583\n",
      "  test loss: 0.256573403778\n",
      "Epoch 71 of 1000 took 1.822s\n",
      "  train loss: 0.0417218646547\n",
      "  test loss: 0.258180736602\n",
      "Epoch 72 of 1000 took 1.585s\n",
      "  train loss: 0.0427394400155\n",
      "  test loss: 0.266483109068\n",
      "Epoch 73 of 1000 took 1.578s\n",
      "  train loss: 0.0390173373035\n",
      "  test loss: 0.268386436981\n",
      "Epoch 74 of 1000 took 1.545s\n",
      "  train loss: 0.0412591846944\n",
      "  test loss: 0.259569032417\n",
      "Epoch 75 of 1000 took 1.505s\n",
      "  train loss: 0.0439915539437\n",
      "  test loss: 0.265386957377\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-cd6be00b22b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mval_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mval_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-259-cd6be00b22b2>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mval_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mval_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgenerate_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-251-ffbbaab0f2b2>\u001b[0m in \u001b[0;36mgenerate_samples\u001b[1;34m(X_true, use_test)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0muser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_users_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mfilm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_items_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlocal_user_to_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-248-1768adaf9b57>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(user, item, X_sample)\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mX_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_to_i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mX_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msmall_features_size\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_film_mk2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[0msmall_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-25a966f9d7b2>\u001b[0m in \u001b[0;36muser_film_mk2\u001b[1;34m(user, item, debug)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mui\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 1000 #amount of passes through the data\n",
    "\n",
    "batch_size = 100 #number of samples processed at each function call\n",
    "num_batches = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in (generate_samples(batch_size, use_test=False) for _ in range(num_batches)):\n",
    "        inputs, targets = batch\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        train_err_batch = train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_batches = 0\n",
    "    for batch in (generate_samples(batch_size, use_test=True) for _ in range(num_batches)):\n",
    "        inputs, targets = batch\n",
    "        targets = targets.reshape((-1, 1))\n",
    "        val_err += loss_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  train loss: %s\" % (train_err / train_batches, ))\n",
    "    print(\"  test loss: %s\" % (val_err / train_batches, ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.99576976],\n",
       "        [ 0.34379049],\n",
       "        [ 0.45306789],\n",
       "        [ 0.18065817],\n",
       "        [ 0.87963364],\n",
       "        [ 0.32685928],\n",
       "        [ 0.30049887],\n",
       "        [ 0.66587964],\n",
       "        [ 0.94503155],\n",
       "        [ 0.66958117]]), array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int8))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generate_random_samples(10, use_test=True)\n",
    "predict(X), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 200\n",
    "batch_size = 1000\n",
    "total_batch = 200\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, features_size]) # mnist data image of shape 28*28=784\n",
    "y = tf.placeholder(tf.float32, [None, 1]) \n",
    "\n",
    "W = tf.Variable(tf.zeros([features_size, 1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "pred = tf.nn.tanh(tf.matmul(x, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(tf.squared_difference(y, pred))\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 0.197359944\n",
      "Epoch: 0002 cost= 0.196920267\n",
      "Epoch: 0003 cost= 0.196819510\n",
      "Epoch: 0004 cost= 0.196147946\n",
      "Epoch: 0005 cost= 0.196093600\n",
      "Epoch: 0006 cost= 0.195149677\n",
      "Epoch: 0007 cost= 0.194767732\n",
      "Epoch: 0008 cost= 0.194793865\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-0ed0d057c661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Loop over all batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_random_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# Fit training using batch data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-c73a02c546d3>\u001b[0m in \u001b[0;36mgenerate_random_samples\u001b[1;34m(X_size, use_test)\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0mfilm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_user_to_items\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = generate_random_samples(batch_size)\n",
    "        batch_ys = batch_ys.reshape((-1, 1))\n",
    "        # Fit training using batch data\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_xs,\n",
    "                                                      y: batch_ys})\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "print (\"Optimization Finished!\")\n",
    "\n",
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "# Calculate accuracy for 3000 examples\n",
    "x_test, y_test =   generate_random_samples(batch_size, use_test=True)\n",
    "y_test = y_test.reshape((-1, 1))\n",
    "print (\"Accuracy:\", cost.eval({x: x_test, y: y_test}, session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.39263499e-06],\n",
       "       [  1.58444379e-06],\n",
       "       [  1.72093326e-06],\n",
       "       [  1.30214175e-06],\n",
       "       [  5.04144646e-06],\n",
       "       [  2.78425546e-06],\n",
       "       [  1.67713119e-06],\n",
       "       [  3.35766458e-06],\n",
       "       [  1.04063997e-06],\n",
       "       [  3.70196062e-06],\n",
       "       [  1.53262081e-05],\n",
       "       [  1.56174860e-06],\n",
       "       [  1.44628314e-06],\n",
       "       [ -2.96540602e-05],\n",
       "       [  1.19626009e-06],\n",
       "       [  1.27234807e-06],\n",
       "       [  3.34417655e-06],\n",
       "       [  9.86953410e-07],\n",
       "       [  2.64779883e-05],\n",
       "       [  5.46258798e-06],\n",
       "       [  4.35487069e-02],\n",
       "       [  4.35487069e-02],\n",
       "       [  2.58548814e-03],\n",
       "       [  4.35487069e-02],\n",
       "       [ -8.12742580e-03],\n",
       "       [  4.35487069e-02],\n",
       "       [  3.76427569e-03],\n",
       "       [  2.90592201e-03],\n",
       "       [  4.35487069e-02],\n",
       "       [  1.27365021e-03],\n",
       "       [  4.00641002e-03],\n",
       "       [  1.73721742e-02],\n",
       "       [  1.39680263e-02],\n",
       "       [  1.39039569e-02],\n",
       "       [  1.31673804e-02],\n",
       "       [  1.03020733e-02],\n",
       "       [  2.82581579e-02],\n",
       "       [ -1.68155297e-03],\n",
       "       [  4.12299559e-02],\n",
       "       [  4.08005714e-03],\n",
       "       [  9.21867013e-01]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.10983541],\n",
       "        [ 0.10352055],\n",
       "        [ 0.20060187],\n",
       "        [ 0.18288017],\n",
       "        [ 0.04566551],\n",
       "        [ 0.19504457],\n",
       "        [ 0.16255407],\n",
       "        [ 0.19504296],\n",
       "        [ 0.00110639],\n",
       "        [ 0.37141779]]), array([0, 0, 0, 1, 1, 0, 1, 0, 1, 0], dtype=int8))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 0.40177947],\n",
       "         [ 0.35771608],\n",
       "         [ 0.35028359],\n",
       "         [ 0.38270113],\n",
       "         [ 0.34994081],\n",
       "         [ 0.39418095],\n",
       "         [ 0.34223077],\n",
       "         [ 0.38585007],\n",
       "         [ 0.42586172],\n",
       "         [ 0.39199695]], dtype=float32)],\n",
       " array([0, 0, 0, 0, 1, 1, 0, 0, 1, 1], dtype=int8))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generate_random_samples(10, use_test=False)\n",
    "sess.run([pred], feed_dict={x: X}), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.98906996e-05,   0.00000000e+00,   5.98360493e-05,\n",
       "          0.00000000e+00,   0.00000000e+00,   3.98906996e-05,\n",
       "          0.00000000e+00,   7.97813991e-05,   1.99453498e-05,\n",
       "          9.97267489e-05,   3.98906996e-05,   3.98906996e-05,\n",
       "         -3.40250190e-05,   1.99453498e-05,   1.99453498e-05,\n",
       "          8.33385002e-06,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.99453498e-05,   1.99453498e-05,   1.00000000e+00,\n",
       "          1.00000000e+00,   2.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          2.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   2.00000000e+00,  -6.53573573e-01,\n",
       "          2.00000000e+00,   1.00000000e+00,   4.65432197e-01,\n",
       "          1.00000000e+00,   1.00000000e+00,   2.00000000e+00,\n",
       "          1.00000000e+00,   1.09823048e-03,   0.00000000e+00], dtype=float32),\n",
       " array([ 0.74074074,  0.09090909,  0.10869565,  0.06      ,  0.12727273,\n",
       "         0.12962963,  0.11111111,  0.12121212,  0.26470588,  0.14925373]),\n",
       " array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int8))"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generate_random_samples(10, use_test=True)\n",
    "X[0], rf.predict(X), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_film_mk3(user, item, debug=False):\n",
    "    X = np.zeros((1, features_size), dtype='float32')\n",
    "    X[0] = extract_features(user, item)\n",
    "    probs = rf.predict(X)\n",
    "    if debug:\n",
    "        print(probs)\n",
    "    return probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_film_mk1(user, item, debug=False):\n",
    "    #print(len(user_features[user]))\n",
    "    cursum = 0\n",
    "    curcnt = 0\n",
    "    if item in films:\n",
    "        for feature, value in films[item].items():\n",
    "            if type(value) is int:\n",
    "                curcnt+=1    \n",
    "                cursum+=value*user_features[user][feature]\n",
    "    if curcnt==0:\n",
    "        curcnt+=1\n",
    "    #cursum/=curcnt\n",
    "    if debug:\n",
    "        print(cursum)\n",
    "    return cursum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_film_mk2(user, item, debug=False):\n",
    "    ui = user_to_i[user]\n",
    "    ii = item_to_i[item]\n",
    "    if debug:\n",
    "        print(ui, ii)\n",
    "    a = np.dot(u[ui,:] * s, vt[:,ii])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_film_mk3('26052b20aa96ed8d803dbfe4e9497192', '45ea2aa2143effcb6575daf0143e31b4', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recommend_mk3_manual(user, n_best = 10, debug=False):\n",
    "    user_items = user_to_items[user]\n",
    "\n",
    "    item_similarities = {}\n",
    "    cur_items = [item for item in all_items if item not in user_items and len(item_to_users[item])>0]\n",
    "    \n",
    "    X = np.zeros((len(cur_items), features_size), dtype='float32')\n",
    "    X_user = extract_features(user)\n",
    "    for i, item in enumerate(cur_items):\n",
    "        X[i] = extract_features(user=None, item=item, X_sample=X_user)\n",
    "    \n",
    "    probs =rf.predict(X)\n",
    "    item_similarities = {key: prob for key, prob in zip(cur_items, probs)}\n",
    "    items_sorted = sorted(all_items, key = lambda x: item_similarities.get(x, 0),reverse = True)\n",
    "    if debug:\n",
    "        print(X)\n",
    "        for a in  items_sorted[:n_best]:\n",
    "            print((a, item_similarities.get(a, 0)))\n",
    "    return items_sorted[:n_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_mk4_manual(user, n_best = 10, debug=False):\n",
    "    user_items = user_to_items[user]\n",
    "\n",
    "    item_similarities = {}\n",
    "    cur_items = [item for item in all_items if item not in user_items and len(item_to_users[item])>0]\n",
    "    \n",
    "    X = np.zeros((len(cur_items), features_size), dtype='float32')\n",
    "    X_user = extract_features(user)\n",
    "    for i, item in enumerate(cur_items):\n",
    "        X[i] = extract_features(user=None, item=item, X_sample=X_user)\n",
    "    \n",
    "    probs =predict(X)\n",
    "    item_similarities = {key: prob for key, prob in zip(cur_items, probs)}\n",
    "    items_sorted = sorted(all_items, key = lambda x: item_similarities.get(x, 0),reverse = True)\n",
    "    if debug:\n",
    "        print(X)\n",
    "        for a in  items_sorted[:n_best]:\n",
    "            print((a, item_similarities.get(a, 0)))\n",
    "    return items_sorted[:n_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generic_recommend(user_flim_function):\n",
    "    def recommend(user, n_best = 10, debug=False):\n",
    "        user_items = user_to_items[user]\n",
    "\n",
    "        item_similarities = {}\n",
    "        for item in all_items:\n",
    "            if item in user_items: continue\n",
    "            item_users = item_to_users[item]\n",
    "            if len(item_users) == 0: continue\n",
    "\n",
    "            item_similarities[item] = user_flim_function(user, item)\n",
    "\n",
    "        items_sorted = sorted(all_items, key = lambda x: item_similarities.get(x, 0),reverse = True)\n",
    "        if debug:\n",
    "            for a in  items_sorted[:n_best]:\n",
    "                print((a, item_similarities.get(a, 0)))\n",
    "        return items_sorted[:n_best]\n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('7682d6641caf183ffcf2616c9bb1e434', 0.08739379)\n",
      "('b5e424608d041f38c2fd6125b3bcd40f', 0.062321573)\n",
      "('006a602774c79d476cdbd5dff7dd24f1', 0.047887065)\n",
      "('e9caaa12a277abf87ba07b84e09a4170', 0.045560129)\n",
      "('aa5f2ca699da42e467e550f9f071fb3f', 0.044249389)\n",
      "('bcee3a68dbfb6b4ea97ac53ceb1d3287', 0.044186898)\n",
      "('e8047b4262e676d28f50816ac3fde1ca', 0.042720947)\n",
      "('77c7998b3d3d41f3fc3aec786b4015ac', 0.038098648)\n",
      "('1da6f84598fbeea050da49fe37297932', 0.037306551)\n",
      "('2dc12b93072f94bca9438902bddc36c4', 0.035170436)\n",
      "10976 651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0024645075"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_recommend(user_film_mk2)('1a337111f63f6a7f86cebf6b2ad3d732', debug=True)\n",
    "user_film_mk2('1a337111f63f6a7f86cebf6b2ad3d732', 'c745ed11b94ed93f3008897c75240de3', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e13df82b3252eaeefc0c13599695f9c7', 0.000658196541476355)\n",
      "('634e622e5c957c2cd8ddb98ca75ef937', 0.0005584697927678163)\n",
      "('8faa6327a2ca2eb92e738ffc204d35c0', 0.0005584697927678163)\n",
      "('64b6536649e20bd72d7183ec717b6c86', 0.0005385244430261086)\n",
      "('5c6d1862dc1e82f340962b308999e603', 0.0005185790932844008)\n",
      "('bcee3a68dbfb6b4ea97ac53ceb1d3287', 0.0005185790932844007)\n",
      "('ef786a839c609561b76ce03768eace80', 0.0005185790932844007)\n",
      "('ff987a60d68f5bbbefe97f8c5062711a', 0.0004986337435426931)\n",
      "('753bce7ac492e6c95b07b85f8877cf5a', 0.0004786883938009853)\n",
      "('7b0f1b0815292c0a550fabd5eeadc011', 0.00045874304405927767)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generic_recommend(user_film_mk1)('1a337111f63f6a7f86cebf6b2ad3d732', debug=True)\n",
    "user_film_mk1('1a337111f63f6a7f86cebf6b2ad3d732', 'c745ed11b94ed93f3008897c75240de3', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.99453498e-05   1.99453498e-05   1.99453498e-05 ...,  -1.06461453e+00\n",
      "    1.00000000e+00  -1.40496281e-10]\n",
      " [  1.99453498e-05   1.99453498e-05   1.99453498e-05 ...,  -3.24740857e-01\n",
      "    1.00000000e+00  -1.40496281e-10]\n",
      " [  1.99453498e-05   1.99453498e-05   1.99453498e-05 ...,   1.64825559e+00\n",
      "    1.00000000e+00  -1.40496281e-10]\n",
      " ..., \n",
      " [  1.99453498e-05   1.99453498e-05   1.99453498e-05 ...,   4.97341007e-01\n",
      "    1.00000000e+00  -1.40496281e-10]\n",
      " [  1.99453498e-05   1.99453498e-05   1.99453498e-05 ...,   2.63475370e+00\n",
      "    1.00000000e+00  -1.40496281e-10]\n",
      " [  1.99453498e-05   1.99453498e-05   1.99453498e-05 ...,  -2.42532656e-01\n",
      "    1.00000000e+00  -1.40496281e-10]]\n",
      "('69491236224f64561ea86be1b18d4a21', array([ 1.]))\n",
      "('e3424765500674cf64431f1c6d9ad99f', array([ 1.]))\n",
      "('83ab67434752ddfbe7051fb09802619c', array([ 1.]))\n",
      "('6863bf647ffb3561460b5f1a45b5fa62', array([ 1.]))\n",
      "('69b09544da4b4c6ff6f6adc3b19e415f', array([ 1.]))\n",
      "('52842279e8fd2bad20fb2b00a20dc952', array([ 1.]))\n",
      "('27d214d6ab24c764da772c9f2c52f040', array([ 1.]))\n",
      "('4f46c808cb70f5c4a1f2ce8b07af20e1', array([ 1.]))\n",
      "('b91c6ae77a0b0ca77f5eda4e11fd9b3d', array([ 0.99999999]))\n",
      "('673985c029d8aff0542e4217da153a3d', array([ 0.99999999]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['69491236224f64561ea86be1b18d4a21',\n",
       " 'e3424765500674cf64431f1c6d9ad99f',\n",
       " '83ab67434752ddfbe7051fb09802619c',\n",
       " '6863bf647ffb3561460b5f1a45b5fa62',\n",
       " '69b09544da4b4c6ff6f6adc3b19e415f',\n",
       " '52842279e8fd2bad20fb2b00a20dc952',\n",
       " '27d214d6ab24c764da772c9f2c52f040',\n",
       " '4f46c808cb70f5c4a1f2ce8b07af20e1',\n",
       " 'b91c6ae77a0b0ca77f5eda4e11fd9b3d',\n",
       " '673985c029d8aff0542e4217da153a3d']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_mk4_manual('a18f526db904f8f2ee4c8d178bfc818c', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a18f526db904f8f2ee4c8d178bfc818c', {'7a040062b953a9a3e7fb1545def5773f'})"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_user_to_items.items())[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_dummy(user, n_best = 10):\n",
    "    item_similarities = []\n",
    "    for item in all_items:\n",
    "        #пропустим те фильмы, которые пользователь уже просмотрел, если нас об этом попросили\n",
    "        if item in user_to_items[user]: continue\n",
    "        item_similarities.append(item)\n",
    "         \n",
    "    random.shuffle(item_similarities)\n",
    "    #вернём n_best наиболее пригодных\n",
    "    #print(items_sorted[:n_best])\n",
    "    return item_similarities[:n_best]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Оценка качества - map@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200\n",
      "100 / 200\n",
      "AP@10 = 9.259259259259259e-05\n"
     ]
    }
   ],
   "source": [
    "check_quality(recommend_dummy,10,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200\n",
      "100 / 200\n",
      "AP@10 = 0.0\n"
     ]
    }
   ],
   "source": [
    "check_quality(recommend_mk3_manual,10, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200\n"
     ]
    }
   ],
   "source": [
    "check_quality(recommend_mk4_manual,100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200\n",
      "100 / 200\n",
      "AP@100 = 0.0014817629179331307\n"
     ]
    }
   ],
   "source": [
    "check_quality(generic_recommend(user_film_mk1),100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200\n",
      "100 / 200\n",
      "AP@100 = 0.007631459343212682\n"
     ]
    }
   ],
   "source": [
    "check_quality(generic_recommend(user_film_mk2),200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 200\n",
      "100 / 200\n",
      "AP@100 = 0.003063415596733874\n"
     ]
    }
   ],
   "source": [
    "check_quality(recommend,100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2732"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_user_to_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#сколько рекоммендаций рассматриваем\n",
    "def check_quality(function, K = 10, max_n_users = len(test_user_to_items)):\n",
    "    APatK_per_user = []\n",
    "    user_list = list(test_user_to_items.keys())[:max_n_users]\n",
    "    \n",
    "    for i, user in enumerate(user_list):\n",
    "        #фильмы, которые пользователю на самом деле нравятся\n",
    "        test_items = test_user_to_items[user]\n",
    "\n",
    "        #Выдать топ-K рекоммендаций\n",
    "        recommendation_list = function(user,n_best=K)\n",
    "        #Посчитать ap@k\n",
    "        user_APatK = apk(test_items, recommendation_list,k=K)\n",
    "\n",
    "        #и сложить в коробку\n",
    "        APatK_per_user.append(user_APatK)\n",
    "\n",
    "        #Progress bar\n",
    "        if i % 100 ==0:\n",
    "            print(i,'/',max_n_users)\n",
    "\n",
    "        if i > max_n_users:\n",
    "            break\n",
    "\n",
    "    print('AP@{} = {}'.format(K, sum(APatK_per_user)/len(APatK_per_user)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Кроме качества рекоммендаций, map@k ещё зависит от доли тестовой выборки, фильтрации и от самого K. Сравнивать качество разных алгоритмов имеет смысл только при одинаковом K и тестовой выборке.\n",
    "* Давать полезные рекоммендации пользователям с малым числом просмотров тоже можно: например, можно выдавать наиболее популярные в целом фильмы.\n",
    "* Разделение на обучение/тест честнее делать на по времени: первые 70% (например) лайков в обучение, остальные в тест. Это ближе к реальной жизни, когда вы сначала обучаете модель на логах, а потом применяете на новых сессиях пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
